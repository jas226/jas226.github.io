Task Notes

How to win:

1. Detect predictive and social biases
2. Identify source(s) of these biases
3. Prevent perpetuation of bias over time
4. Provide proof-of-concept as a tool that supports broad use of AI algorithms

[x] Register by Feb 15th

Code should be stored as two python scripts (.py files):
  “measure_disparity.py” takes in a set of model predictions and quantifies discrimination in model outcomes
  “mitigate_disparity.py” takes in a model development dataset (training and test datasets) that your algorithm has not seen before and generates a new, optimally fair/debiased model that can be used to make new predictions.

Supporting documentation is required to be in PDF format and must not exceed 10 pages. Please refer to the template AVAILABLE HERE for guidance on content to address the following topics: 

1. Methodology Overview
  -What metrics did you choose to identify different types of bias and why? Which types of bias did you identify and how? 
  -How does your bias detection tool measure retrospective and prospective bias?  
  -How does your tool detect “latent” bias or drift? 
  -What creative or novel approaches did you incorporate in your bias detection tool? 
  -If the tool creatively departs from existing practices and standards, how well-justified are those departures?  
  -What was your inspiration for this methodology?  
  
2. Value Proposition
 - What types of biases are you addressing and how accurately does your tool identify bias within the algorithm?  
 -What appropriate metrics are proposed to identify the bias?  
 -Did the tool identify the type of bias inherent in the algorithm? 
 -Is the bias predictive and/or social and how did the tool identify these biases? 

3. Healthcare Scenario
 -How does your tool detect “latent” bias, (i.e., increases in social or statistical biases over time due to the complexities of healthcare processes)? 
 -What recommendations did your tool suggest to identify the underlying root(s) of the biases detected? Who would be responsible for investigating cause and remediation options? How easily could the tool be implemented to perform this task?  
 -How will your bias detection tool, when implemented as described here, improve healthcare over time and for all patient populations? 

4. Operational Requirements
  -Can this tool be deployed widely and if so, is an SOP and/or code etc. provided for implementation at other locations?  
  -Are there any dependencies on vendors or proprietary information exchange standards that would limit the tool’s impact? 
  -What is your architectural design and how do you ensure it is technology-agnostic?  
  -Do you acknowledge that the tool will be distributed under the BSD 3 license? 

5. Sustainability Plan
 -Does your plan take into account or involve the multidisciplinary team and expertise needed for implementation in real-world settings? 
 -Does your tool accurately calculate retrospective (measuring performance of the clinical decision model when developed) and prospective (measuring performance continuity/in real world application) metrics?  
 -Can the tool be used in the future without significant upkeep costs? 

6. Generalizability Plan
 - How impactful is the tool? Who can use this tool and how likely are they to use it? How easily can the target user run it on an ongoing basis to monitor and continually improve bias mitigation practices? How easily could your tool be applied to other and broader types of clinical decisions, i.e. predictions, diagnoses, or treatment recommendations? 
 -Can this tool be deployed widely and if so, is an SOP and/or code etc. provided for implementation at other locations? How easily could your tool be leveraged in other clinical disciplines or with other types of health information, e.g. cardiology, oncology, obstetrics, etc.? 
 -What are the next steps for this tool? Can this tool be implemented as is or does it need additional support? 
 -Did the tool suggest follow-up investigations to identify the underlying root(s) of the biases detected? How easily could the tool be implemented to perform this task? 
 -Does the tool seem likely to improve health equity (fairness) and trust in AI/ML in healthcare settings? 
 -How easily could your tool be applied to other and broader types of clinical decisions, i.e. predictions, diagnoses, or treatment recommendations? 
 -How easily could your tool be leveraged in other clinical disciplines or with other types of health information, e.g. cardiology, oncology, obstetrics, etc.? 

7. Implementation Requirements

  -Do the implementation strategy and SOPs take into account or involve the multidisciplinary team and expertise needed for implementation in real-world settings? 
  -Can this tool be deployed widely and if so, is an SOP and/or code etc. provided for implementation at other locations? 
  -Describe the human resources needed to implement in a real-world setting?  
  -How do you measure success of the implementation?  

8. Lessons Learned
  - How will your tool, next year or three years from now, improve health equity (fairness) and trust in AI/ML in healthcare settings? 
  - Are there other ways your tool can be used, perhaps in a research or government setting, to improve healthcare outcomes? or address other social inequities? 

[]Setup Github for Submission
  [x] GitHub Pages Site
  [x] Script Components Visible on Site
     [x] “measure_disparity.py” visible
     [x] "mitigate_disparity.py" visible
  [] Theme Components Visible
  [] Supporting documentation visible
[x] Webinar 1
[x] Webinar 2
[] Webinar 3
[x] Formulate Project Topic/Healthcare Scenario
[] view SOLAI's tool
[] How will the tool be used?
[] Collect Data
[] Understand Data
[] Create models
[] Train models
[] Test models
[] Model Application 
[] Build React App
[] Cloud Run Configuration
[] Disciplinary Research
[] Submit
[] Complete Challenge 
